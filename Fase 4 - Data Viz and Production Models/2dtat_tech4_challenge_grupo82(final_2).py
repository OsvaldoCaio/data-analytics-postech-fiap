# -*- coding: utf-8 -*-
"""2DTAT_Tech4_Challenge_Grupo82(Final_2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1swgWKXr5sfZ1XN_nNCS2SD4nTSZ8S59i

#Importando Bibliotecas
"""

#Se necessário, instalar tirando o # das linhas inferiores
#!pip install statsforecast
#!pip install --upgrade statsmodels
#!pip install pmdarima
#!pip install prophet
#!pip install sklearn

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import export_graphviz

from prophet import Prophet
from prophet.diagnostics import cross_validation, performance_metrics

from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.optimizers import Adam
from keras.metrics import MeanSquaredError as KerasMeanSquaredError
from keras.preprocessing.sequence import TimeseriesGenerator
from keras.losses import MeanSquaredError

import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objs as go

"""#Dados

##Preço
"""

df = pd.read_html('http://www.ipeadata.gov.br/ExibeSerie.aspx?module=m&serid=1650971490&oper=view', skiprows=1, thousands='.', decimal=',')[0]
df.head()

def excluiDadosNulos(df):
    if 0 not in df.isna().sum().values:
        df = df.dropna()

def tipaDados(df):
    df['data'] = df['data'].str.replace('/', '-')
    df['data'] = pd.to_datetime(df['data'], format='%d-%m-%Y')
    return df

def renomeiaColunas(df):
    df.rename(columns={0: 'data', 1: 'preco'}, inplace=True)
    return df

df = renomeiaColunas(df)
df.head()

df.head()

df.info()

#df['data'] = pd.to_datetime(df['data'])
df['data'] = pd.to_datetime(df['data'], format="%d/%m/%Y")
# Exibindo o DataFrame após a conversão
print(df)

df.isnull().sum()

df.shape

df.describe().T

plt.figure(figsize=(15, 10))
plt.plot(df['data'], df['preco'], label='Preço Barril')
plt.xlabel('Anos')
plt.ylabel('Preço')
plt.legend(loc='best')
plt.show()

#Filtrando os dados
df = df[['preco', 'data']].set_index('data')

df['MM30'] = df['preco'].rolling(30).mean().shift() #média móvel
df['MM180'] = df['preco'].rolling(180).mean().shift() #média móvel

#Rolling para deslocamento. Este parâmetro especifica o número de observações usadas para calcular a estatística
#shift é utilizado para deslocar o índice de DataFrame por um número especificado de períodos com uma freqüência de tempo opcional

df.head()

df.tail()

#pq o indice é importante
df.loc['2020-08-07']

df.index = pd.to_datetime(df.index, format='%Y-%m-%d')

plt.figure(figsize=(15,10))
plt.grid(True)
plt.plot(df['preco'], label='Preço')
plt.plot(df['MM30'], label='MM janela 30 dias')
plt.plot(df['MM180'], label='MM janela 180 dias')
plt.xlabel('Anos')
plt.ylabel('Preço')
plt.legend(loc=2)
plt.show()

import matplotlib.pyplot as plt

# Certifique-se de que o índice do DataFrame seja do tipo DateTime
df.index = pd.to_datetime(df.index)

limit = 2000

plt.figure(figsize=(15, 10))
plt.grid(True)
plt.plot(df.reset_index()['preco'][-limit:], label='Preço')
plt.plot(df.reset_index()['MM30'][-limit:], label='MM janela 30 dias')
plt.plot(df.reset_index()['MM180'][-limit:], label='MM janela 180 dias')
plt.xlabel('Data')  # Define o rótulo do eixo x como 'Data'
plt.ylabel('Preço')
plt.legend(loc=2)

# Define os rótulos do eixo x como datas
plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y'))

plt.xticks(rotation=45)  # Rotaciona os rótulos do eixo x para melhor legibilidade
plt.show()

limit = 2000

# Redefinir o índice
#df.reset_index(drop=True, inplace=True)

plt.figure(figsize=(15, 10))
plt.grid(True)
plt.plot(df['preco'][-limit:], label='Preço')
plt.plot(df['MM30'][-limit:], label='MM janela 30 dias')
plt.plot(df['MM180'][-limit:], label='MM janela 180 dias')
plt.xlabel('Anos')
plt.ylabel('Preço')
plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y'))
plt.legend(loc=2)
plt.show()

"""##Desvio Padrão"""

# Armazene o DataFrame original antes de resetar
#df_original = df.copy()
# Reset do índice
#df.reset_index(drop=True, inplace=True)
# Se agora você quiser restaurar o DataFrame original com o índice
#df = df_original.copy()
# Supondo que 'data' seja o nome da coluna que você deseja converter para datetime
#df['data'] = pd.to_datetime(df.index)

# Calcular desvio padrão móvel
window = 30  # Janela de 30 dias
df['DesvioPadrao'] = df['preco'].rolling(window=window).std()

# Plotar usando Seaborn
plt.figure(figsize=(15, 10))

sns.lineplot(data=df, x='data', y='preco', label='Preço')
sns.lineplot(data=df, x='data', y='DesvioPadrao', label='Desvio Padrão Móvel 30 Dias', color='green')

# Estilização do gráfico
plt.xlabel('Anos')
plt.ylabel('Preço')

# Ajustando o formato das datas no eixo x
plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y'))

plt.title('Desvio Padrão Móvel e Preço ao longo do tempo')

plt.legend()
plt.tight_layout()
plt.show()

"""##As Bandas de Bollinger"""

# Calcular média móvel e desvio padrão
window = 30
df['MM30'] = df['preco'].rolling(window=window).mean()
df['DesvioPadrao'] = df['preco'].rolling(window=window).std()

# Calculando as Bollinger Bands
k = 2
df['Banda Superior'] = df['MM30'] + (df['DesvioPadrao'] * k)
df['Banda Inferior'] = df['MM30'] - (df['DesvioPadrao'] * k)

# Plotar usando Seaborn
plt.figure(figsize=(15, 10))

palette = sns.color_palette("Set1")

sns.lineplot(data=df, x='data', y='preco', label='Preço', color=palette[5])
sns.lineplot(data=df, x='data', y='MM30', label='Média Móvel 30 Dias', color=palette[2])
sns.lineplot(data=df, x='data', y='Banda Superior', label='Banda Superior', color=palette[1])
sns.lineplot(data=df, x='data', y='Banda Inferior', label='Banda Inferior', color=palette[0])

# Estilização do gráfico
plt.xlabel('Anos')
plt.ylabel('Preço')
plt.title('Série de Preço com as bandas de Bollinger')

plt.legend()
plt.tight_layout()
plt.show()

#pq o indice é importante
#df.loc['2020-08-07']

"""##Decomposição e Dickey-Fuller"""

resultados = seasonal_decompose(df['preco'], model='additive', period=12)

fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(15, 10))

resultados.observed.plot(ax=ax1, label='Ibovespa')
ax1.set_ylabel('Série Temporal Observada')
ax1.set_xlabel('Anos')

resultados.trend.plot(ax=ax2)
ax2.set_ylabel('Tendência')
ax2.set_xlabel('Anos')

resultados.seasonal.plot(ax=ax3)
ax3.set_ylabel('Componente Sazonal')
ax3.set_xlabel('Anos')

resultados.resid.plot(ax=ax4)
ax4.set_ylabel('Resíduos')
ax4.set_xlabel('Anos')

plt.suptitle('Decomposição da Série Temporal', fontsize=16)
plt.tight_layout()
plt.show()

"""# ARIMA - Redução da Série Temporal - 1º ACF| PACF

##Determinando datas
"""

df = df.sort_index(ascending=True)

print(df)

#Determinando o range para trabalhar, depois de 2020 da pandemia
start_date_new = '2023-01-01'
end_date_new = '2024-03-30'

# Filtrar as datas desejadas
df_1 = df[(df.index >= start_date_new) & (df.index <= end_date_new)]

df_1.head()

df_1['preco'].tail()

print(df)

# Cálculo da ACF e PACF para as colunas 'data' e 'preco' do DataFrame
lag_acf = acf(df_1['preco'], nlags=40)  # Autocorrelation Function (ACF)
lag_pacf = pacf(df_1['preco'], nlags=40, method='ols')  # Partial Autocorrelation Function (PACF)
conf_int = 1.96 / np.sqrt(len(df_1['preco']))  # Intervalo de confiança

plt.plot(lag_acf)

plt.axhline(y= -1.96/(np.sqrt((len(df_1) -1))), linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 0, linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 1.96/(np.sqrt((len(df_1) -1))), linestyle='--', color='gray', linewidth=0.7)

plt.title("ACF")
plt.show()

plt.plot(lag_pacf)

plt.axhline(y= -1.96/(np.sqrt((len(df_1) -1))), linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 0, linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 1.96/(np.sqrt((len(df_1) -1))), linestyle='--', color='gray', linewidth=0.7)

plt.title("PACF")
plt.show()

"""##Decomposição e Dickey-Fuller"""

resultados = seasonal_decompose(df_1['preco'], model='additive', period=12)

fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(15, 10))

resultados.observed.plot(ax=ax1, label='Preço')
ax1.set_ylabel('Série Temporal Observada')
ax1.set_xlabel('Anos')

resultados.trend.plot(ax=ax2)
ax2.set_ylabel('Tendência')
ax2.set_xlabel('Anos')

resultados.seasonal.plot(ax=ax3)
ax3.set_ylabel('Componente Sazonal')
ax3.set_xlabel('Anos')

resultados.resid.plot(ax=ax4)
ax4.set_ylabel('Resíduos')
ax4.set_xlabel('Anos')

plt.suptitle('Decomposição da Série Temporal', fontsize=16)
plt.tight_layout()
plt.show()

X = df_1.preco.values

result = adfuller(X)

print("Teste ADF")
print(f"Teste estatístico: {result[0]}")
print(f"P-Value: {result[1]}")
print("Valores críticos:")

for key, value in result[4].items():
  print(f"\t{key}: {value}")

"""No seu caso, o valor-p é 0.0958, que é maior do que o nível de significância comumente usado de 0.05. Isso significa que não temos evidências suficientes para rejeitar a hipótese nula de que a série possui raiz unitária, ou seja, não podemos concluir que a série é estacionária com base apenas neste teste."""

#media movel
ma = df_1['preco'].rolling(12).mean()

f, ax = plt.subplots()

df_1['preco'].plot(ax=ax, legend=True, label='Dados')
ma.plot(ax=ax, color="r", legend=True, label='Média Móvel')
plt.xlabel('Anos')
plt.tight_layout()

#aplicar log (transformando escala)
df_log = np.log(df_1['preco'])
ma_log = df_log.rolling(12).mean()

f, ax = plt.subplots()
df_log.plot(ax=ax, legend=True, label='Dados')
ma_log.plot(ax=ax, color="r", legend=True, label='Média Móvel')
plt.xlabel('Anos')
plt.tight_layout()

#fez o drop na para que seja retirado valores nulos - o 12 é fazendo apenas dos 12 meses
df_1_s = (df_log - ma_log).dropna() #subtrai da média

ma_s = df_1_s.rolling(12).mean() #média móvel

std = df_1_s.rolling(12).std() #desvio padrao

f, ax = plt.subplots()
df_1_s.plot(ax=ax, legend=True, label='Dados')
ma_s.plot(ax=ax, color="r", legend=True, label='Média Móvel')
std.plot(ax=ax, color="g", legend=True, label='Desvio Padrão')
plt.xlabel('Anos')
plt.tight_layout()

"""##Teste ADF Novamente"""

X_s = df_1_s.values
result_s = adfuller(X_s)

print("Teste ADF")
print(f"Teste estatístico: {result_s[0]}")
print(f"P-Value: {result_s[1]}")
print("Valores críticos:")

for key, value in result_s[4].items():
  print(f"\t{key}: {value}")

"""Dado que o valor-p é extremamente baixo (2.3668591304456707e-05) e é menor que o nível de significância comumente utilizado de 0.05, podemos rejeitar a hipótese nula de que a série possui raiz unitária. Isso sugere que há evidências suficientes para concluir que a série é estacionária.

##Diferenciação
"""

#1 derivada
df_diff = df_1_s.diff(1)
ma_diff = df_diff.rolling(12).mean()

#desvio padrão
std_diff = df_diff.rolling(12).std()

f, ax = plt.subplots()
df_diff.plot(ax=ax, legend=True, label='Dados')
ma_diff.plot(ax=ax, color="r", legend=True, label='Média Móvel')
std_diff.plot(ax=ax, color="g", legend=True, label='Desvio Padrão')
plt.xlabel('Anos')
plt.tight_layout()

X_diff = df_diff.dropna().values#tem q dropar
result_diff = adfuller(X_diff)

print("Teste ADF")
print(f"Teste estatístico: {result_diff[0]}")
print(f"P-Value: {result_diff[1]}")
print("Valores críticos:")

for key, value in result_diff[4].items():
  print(f"\t{key}: {value}")

"""p-value está cada vez mais proximo de zero

Ela é estacionaria.

#ARIMA - após diferenciação
"""

lag_acf = acf(df_diff.dropna(), nlags=25)
lag_pacf = pacf(df_diff.dropna(), nlags=25)

plt.plot(lag_acf)

plt.axhline(y= -1.96/(np.sqrt((len(df_diff) -1))), linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 0, linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 1.96/(np.sqrt((len(df_diff) -1))), linestyle='--', color='gray', linewidth=0.7)

plt.title("ACF")
plt.show()

plt.plot(lag_pacf)

plt.axhline(y= -1.96/(np.sqrt((len(df_diff) -1))), linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 0, linestyle='--', color='gray', linewidth=0.7)
plt.axhline(y= 1.96/(np.sqrt((len(df_diff) -1))), linestyle='--', color='gray', linewidth=0.7)

plt.title("PACF")
plt.show()

"""NO ARIMA - FUNCIONARIA ASSIM:

* A(x,y, z)
* x= é onde o ponto pega no limite superior na primeira vez do ACF que seria o numero 18
* y = é onde o ponto passa o limite superir no PACF na primeira vez - que seria 1
"""

plot_acf(df_1_s)
plot_pacf(df_1_s)

plt.show()

"""* o cone azul é a largura banda de confiança
* a correlação parcial, tem a negativa

Conclusão

Ao observar os gráficos de ACF e PACF, notamos que ambos representam consistentemente o intervalo de confiança em todos os lags. Isso sugere que, após a diferenciação, a série temporal não apresenta autocorrelações significativas em seus lags. Esse é um bom indicativo de que a diferenciação foi eficaz em remover padrões e tendências da série, tornando-a estacionária e, assim, mais adequada para modelagem ARIMA.

##RSS
"""

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt

# Resetando o índice do DataFrame
df_1_s_reset = df_1_s.reset_index(drop=True)

# Criando o modelo ARIMA
model = ARIMA(df_1_s_reset, order=(1, 1, 0))  # (p, d, q)

# Ajustando o modelo
results_AR = model.fit()

# Criando o gráfico
plt.figure(figsize=(15, 8))
plt.plot(df_1_s_reset)
plt.plot(results_AR.fittedvalues, color='g')
plt.title('RSS: %.4f' % sum((results_AR.fittedvalues - df_1_s_reset)**2))
plt.xlabel('Anos')
plt.show()

print('Plotting AR model')

"""Uma RSS de 0,1138, nesse contexto, indica que há uma quantidade de variabilidade não explicada pelo modelo, pois os resíduos não são todos iguais a zero. Quanto menor for a RSS, melhor o modelo se ajusta aos dados, pois isso indica que os resíduos são menores, ou seja, que o modelo está explicando uma maior proporção da variabilidade nos dados observados.

##MAPE
"""

# Obtenha as previsões
predictions = results_AR.fittedvalues

# Ajuste os índices para garantir correspondência
predictions.index = df_1_s.index

# Inverta a diferenciação
# (indexedDataset_logScale['Close'].iloc[0]) para inverter a diferenciação.
# np.cumsum(predictions) é usado para calcular a soma cumulativa das previsões.
predicted_values = df_log.iloc[0] + np.cumsum(predictions)

# Calcule o MAPE
mape = mean_absolute_error(df_1_s, predicted_values) * 100

print(f"MAPE: {mape:.2f}%")

"""Quando você vê um MAPE de 454.45%, isso significa que, em média, os erros absolutos das previsões do seu modelo são cerca de 454.45%% do valor real.

##Prophet
"""

df.tail()

df_1.tail()

from datetime import datetime

# Definindo a data de início como 2023-01-01
data_inicio = datetime(2023, 1, 1)

# Definindo a data final como a data de hoje
data_fim = datetime.now()

# Resetando o índice para tornar a coluna 'data' acessível novamente
df_reset = df.reset_index()

# Renomeando as colunas e criando a coluna 'unique_id'
df = df_reset[['data', 'preco']].rename(columns={'data': 'ds', 'preco': 'y'})
df['unique_id'] = 'Preco'
df.dropna(inplace=True)

# Filtrando o DataFrame para incluir apenas os dados entre a data de início e a data final
df = df[(df['ds'] >= data_inicio) & (df['ds'] <= data_fim)]

df.head()

# Resetando o índice para tornar a coluna 'data' acessível novamente
#df_reset = df.reset_index()

# Renomeando as colunas e criando a coluna 'unique_id'
#df = df_reset[['data', 'preco']].rename(columns={'data': 'ds', 'preco': 'y'})
#df['unique_id'] = 'Preco'
#df.dropna(inplace=True)
#df.head()

train_data = df.sample(frac=0.8, random_state=0)
test_data = df.drop(train_data.index)
print(f'training data size : {train_data.shape}')
print(f'testing data size : {test_data.shape}')

modelo = Prophet(daily_seasonality=True)
modelo.fit(train_data)
dataFramefuture = modelo.make_future_dataframe(periods=24, freq='M')
previsao = modelo.predict(dataFramefuture)
previsao.head()

modelo.plot(previsao, figsize=(20,6));
plt.plot(test_data['ds'], test_data['y'], '.r')

modelo.plot_components(previsao, figsize=(15,10));

# Extrair as colunas relevantes dos DataFrames
previsao_cols = ['ds', 'yhat']
valores_reais_cols = ['ds', 'y']

previsao = previsao[previsao_cols]
valores_reais = train_data[valores_reais_cols]

# Mesclar os DataFrames nas colunas 'ds' para comparar previsões e valores reais
resultados = pd.merge(previsao, valores_reais, on='ds', how='inner')

# Calcular o erro percentual absoluto para cada ponto de dados
resultados['erro_percentual_absoluto'] = np.abs((resultados['y'] - resultados['yhat']) / resultados['y']) * 100

# Calcular o MAPE
mape = np.mean(resultados['erro_percentual_absoluto'])

print(f"MAPE: {mape:.2f}%")

"""Portanto, um MAPE de 2,99% significa que, em média, as previsões do modelo têm um erro absoluto médio de 2,99% em relação aos valores reais.

##Cross Validation
"""

df_cv = cross_validation(modelo, initial='360 days', period='30 days', horizon = '30 days')

df_cv.head()

df_p = performance_metrics(df_cv)
df_p

"""##Algoritimo LSTM (Long Short-Term Memory)"""

df_1.tail()

df_1.reset_index(inplace=True)
df_1.drop(columns=['MM30', 'MM180', 'DesvioPadrao', 'Banda Superior', 'Banda Inferior'], inplace=True)
df_1.rename(columns={'ds': 'data', 'y': 'preco'}, inplace=True)
df = df_1
df.tail()

df.info()

close_data = df['preco'].values
close_data = close_data.reshape(-1,1) #transformar em array

"""##Normalizando os dados"""

#df.reset_index(inplace=True)

#df_1.reset_index(inplace=True)

scaler = MinMaxScaler(feature_range=(0, 1))
scaler = scaler.fit(close_data)
close_data = scaler.transform(close_data)

split_percent = 0.80
split = int(split_percent*len(close_data))

close_train = close_data[:split]
close_test = close_data[split:]

date_train = df['data'][:split]
date_test = df['data'][split:]

print(len(close_train))
print(len(close_test))

# Gerar sequências temporais para treinamento e teste em um modelo de aprendizado de máquina

look_back = 10

train_generator = TimeseriesGenerator(close_train, close_train, length=look_back, batch_size=20)
test_generator = TimeseriesGenerator(close_test, close_test, length=look_back, batch_size=1)

from keras.losses import MeanSquaredError  # Importing MeanSquaredError class

np.random.seed(43)

model = Sequential()
model.add(LSTM(100, activation='relu', input_shape=(look_back,1)))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError()])

num_epochs = 20
model.fit(train_generator, epochs=num_epochs, verbose=1)

np.random.seed(43)

model = Sequential()
model.add(LSTM(100, activation='relu', input_shape=(look_back,1)))
model.add(Dense(1)),

model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError()])

num_epochs = 20
model.fit(train_generator, epochs=num_epochs, verbose=1)

"""##MSE"""

# Avaliando o modelo nos dados de teste
mse = model.evaluate(test_generator, verbose=1)
print("Erro Quadrático Médio", mse[0])

"""![image.png](data:image/png;base64,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)

um MSE de 0.002752686617895961 significa que, em média, os quadrados dos erros das previsões do modelo são 0.002752686617895961. Em outras palavras, o MSE mede a média dos quadrados dos desvios das previsões em relação aos valores verdadeiros. Quanto menor o valor do MSE, melhor é a precisão do modelo em relação aos dados observados.

MAPE
"""

# 1. Fazer previsões usando o conjunto de teste
test_predictions = model.predict(test_generator)

# 2. Inverter qualquer transformação aplicada aos dados
test_predictions_inv = scaler.inverse_transform(test_predictions.reshape(-1, 1))
test_actuals_inv = scaler.inverse_transform(np.array(close_test).reshape(-1, 1))

# Ajuste as dimensões
test_actuals_inv = test_actuals_inv[:len(test_predictions_inv)]

# Calcular o MAPE
mape = np.mean(np.abs((test_actuals_inv - test_predictions_inv) / test_actuals_inv)) * 100

# Imprimir o MAPE
print(f'MAPE: {mape:.4f}')

"""![image.png](data:image/png;base64,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)

O MAPE de 2,2634% indica que, em média, as previsões do modelo têm um erro absoluto médio de 2,2634% em relação aos valores reais. Isso significa que, em média, as previsões do modelo estão incorretas em cerca de 2,2634% em relação aos valores reais.

##RMSE
"""

#O RMSE é a raiz quadrada do MSE (Mean Squared Error),
#que é a média dos quadrados das diferenças entre as previsões do modelo e os valores reais.
rmse_value = np.sqrt(mse[0])

print("RMSE:", rmse_value)

"""![image.png](data:image/png;base64,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)

um RMSE de 0.052466052051740666 significa que, em média, o desvio padrão dos erros das previsões do modelo é de 0.052466052051740666. Em outras palavras, o RMSE fornece uma medida da dispersão dos erros das previsões em relação aos valores verdadeiros. Quanto menor o valor do RMSE, melhor é a precisão do modelo em relação aos dados observados.

#Predição
"""

prediction = model.predict(test_generator)

close_train = close_train.reshape((-1))
close_test = close_test.reshape((-1))
prediction = prediction.reshape((-1))

trace1 = go.Scatter(
    x = date_train,
    y = close_train,
    mode = 'lines',
    name = 'Data'
)
trace2 = go.Scatter(
    x = date_test,
    y = prediction,
    mode = 'lines',
    name = 'Prediction'
)
trace3 = go.Scatter(
    x = date_test,
    y = close_test,
    mode='lines',
    name = 'Ground Truth'
)
layout = go.Layout(
    title = "Predições",
    xaxis = {'title' : "Data"},
    yaxis = {'title' : "Preço"}
)
fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)
fig.show()

"""##Validando com suavização da série temporal"""

df.tail()

# Suazivando a série temporal
# Aplicando suavização exponencial
alpha = 0.09   # Fator de suavização
# O parâmetro alpha na suavização exponencial controla a taxa de decaimento dos pesos atribuídos às observações passadas.
# Determina o quão rapidamente o impacto das observações antigas diminui à medida que você avança no tempo.

df['Smoothed_Close'] = df['preco'].ewm(alpha=alpha, adjust=False).mean()

plt.figure(figsize=(12, 6))
plt.plot(df.index, df['preco'], label='Original', color='blue')
plt.plot(df.index, df['Smoothed_Close'], label=f'Suavizado (alpha={alpha})', color='g')
plt.title('Série Temporal Suavizada usando Suavização Exponencial')
plt.xlabel('Data')
plt.ylabel('Preço do barril')
plt.legend()
plt.show()

"""## Teste de estacionariedade (ADF Test)"""

# Teste de estacionariedade (ADF Test)
adf_result = adfuller(df['Smoothed_Close'] )
print(f'ADF Statistic: {adf_result[0]}')
print(f'p-value: {adf_result[1]}')
print('Resultados do Teste de Estacionariedade:')
print('--------------------------------------')
print('Teste Estatístico:', adf_result[0])
print('Valor-p:', adf_result[1])
print('Valores Críticos:')
for key, value in adf_result[4].items():
    print(f'   {key}: {value}')

df.drop(columns=['preco'], inplace=True)
df.head()

close_data = df['Smoothed_Close'].values
close_data = close_data.reshape(-1,1) #transformar em array

scaler = MinMaxScaler(feature_range=(0, 1))
scaler = scaler.fit(close_data)
close_data = scaler.transform(close_data)

close_data

split_percent = 0.80
split = int(split_percent*len(close_data))

close_train = close_data[:split]
close_test = close_data[split:]

date_train = df['data'][:split]
date_test = df['data'][split:]

print(len(close_train))
print(len(close_test))

# Gerar sequências temporais para treinamento e teste em um modelo de aprendizado de máquina
look_back = 5

train_generator = TimeseriesGenerator(close_train, close_train, length=look_back, batch_size=20)
test_generator = TimeseriesGenerator(close_test, close_test, length=look_back, batch_size=1)

np.random.seed(43)

model = Sequential()
model.add(LSTM(100, activation='relu', input_shape=(look_back,1)))
model.add(Dense(1)),

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mse', metrics=[MeanSquaredError()])

num_epochs = 100
model.fit(train_generator, epochs=num_epochs, verbose=1)

# 1. Fazer previsões usando o conjunto de teste
test_predictions = model.predict(test_generator)

# 2. Inverter qualquer transformação aplicada aos dados
test_predictions_inv = scaler.inverse_transform(test_predictions.reshape(-1, 1))
test_actuals_inv = scaler.inverse_transform(np.array(close_test).reshape(-1, 1))

# Ajuste as dimensões
test_actuals_inv = test_actuals_inv[:len(test_predictions_inv)]

# Calcular o MAPE
mape = np.mean(np.abs((test_actuals_inv - test_predictions_inv) / test_actuals_inv)) * 100

# Imprimir o MAPE
print(f"MAPE: {mape:.2f}%")

# Avaliando o modelo nos dados de teste
mse = model.evaluate(test_generator, verbose=1)
print("Erro Quadrático Médio:", mse[0])

# O RMSE é a raiz quadrada do MSE (Mean Squared Error),
#que é a média dos quadrados das diferenças entre as previsões do modelo e os valores reais.
rmse_value = np.sqrt(mse[0])
print("RMSE:", rmse_value)

prediction = model.predict(test_generator)

close_train = close_train.reshape((-1))
close_test = close_test.reshape((-1))
prediction = prediction.reshape((-1))

trace1 = go.Scatter(
    x = date_train,
    y = close_train,
    mode = 'lines',
    name = 'Data'
)
trace2 = go.Scatter(
    x = date_test,
    y = prediction,
    mode = 'lines',
    name = 'Prediction'
)
trace3 = go.Scatter(
    x = date_test,
    y = close_test,
    mode='lines',
    name = 'Ground Truth'
)
layout = go.Layout(
    title = "Predições",
    xaxis = {'title' : "Data"},
    yaxis = {'title' : "Preço"}
)
fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)

fig.update_layout(
    autosize=False,
    width=1200,  # Largura em pixels
    height=800,  # Altura em pixels
)

fig.show()

"""#forecasting"""

close_data = close_data.reshape((-1))
# Função para prever os próximos 'num_prediction' pontos da série temporal
# Utiliza o modelo treinado para prever cada ponto sequencialmente
# A cada iteração, adiciona a previsão à lista 'prediction_list'

def predict(num_prediction, model):
    prediction_list = close_data[-look_back:]

    for _ in range(num_prediction):
        x = prediction_list[-look_back:]
        x = x.reshape((1, look_back, 1))
        out = model.predict(x)[0][0]
        prediction_list = np.append(prediction_list, out)
    prediction_list = prediction_list[look_back-1:]

    return prediction_list

# Função para gerar as datas dos próximos 'num_prediction' dias
# Assume que o DataFrame 'df' possui uma coluna 'Date' contendo as datas
def predict_dates(num_prediction):
    last_date = df['data'].values[-1]
    prediction_dates = pd.date_range(last_date, periods=num_prediction+1).tolist()
    return prediction_dates

num_prediction = 30 #definição dos próximos dias
forecast = predict(num_prediction, model) #resultado de novos dias
forecast_dates = predict_dates(num_prediction)

trace1 = go.Scatter(
    x = date_test,
    y = close_test,
    mode = 'lines',
    name = 'Data'
)
trace2 = go.Scatter(
    x = forecast_dates,
    y = forecast,
    mode = 'lines',
    name = 'Prediction'
)
layout = go.Layout(
    title = "Forecast",
    xaxis = {'title' : "Data"},
    yaxis = {'title' : "Preço"}
)
fig = go.Figure(data=[trace1, trace2], layout=layout)
fig.show()

"""##Organizando os dados em um dataframe"""

df = pd.DataFrame(df)
df_past = df[['data','Smoothed_Close']]
df_past.rename(columns={'Smoothed_Close': 'Actual'}, inplace=True)         #criando nome das colunas
df_past['data'] = pd.to_datetime(df_past['data'])                          #configurando para datatime
df_past['Forecast'] = np.nan                                               #Preenchendo com NAs
df_past['Forecast'].iloc[-1] = df_past['Actual'].iloc[-1]
df_past.head(3)

# Faz a transformação inversa das predições
forecast = forecast.reshape(-1, 1) #reshape para array
forecast = scaler.inverse_transform(forecast)

df_future = pd.DataFrame(columns=['data', 'Actual', 'Forecast'])
df_future['data'] = forecast_dates
df_future['Forecast'] = forecast.flatten()
df_future['Actual'] = np.nan
df_future.head()

# Concatenando os DataFrames usando concat
frames = [df_past, df_future]
results = pd.concat(frames, ignore_index=True).set_index('data')
results.head(5)

results.tail(5)

print(results)

results.tail(30)

